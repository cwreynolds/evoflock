@misc{antipov_evolutionary_2025,
	title = {Evolutionary {Algorithms} {Are} {Significantly} {More} {Robust} to {Noise} {When} {They} {Ignore} {It}},
	url = {http://arxiv.org/abs/2409.00306},
	doi = {10.48550/arXiv.2409.00306},
	abstract = {Randomized search heuristics (RSHs) are known to have a certain robustness to noise. Mathematical analyses trying to quantify rigorously how robust RSHs are to a noisy access to the objective function typically assume that each solution is re-evaluated whenever it is compared to others. This aims at preventing that a single noisy evaluation has a lasting negative effect, but is computationally expensive and requires the user to foresee that noise is present (as in a noise-free setting, one would never re-evaluate solutions). In this work, we conduct the first mathematical runtime analysis of an evolutionary algorithm solving a single-objective noisy problem without re-evaluations. We prove that the \$(1+1)\$ evolutionary algorithm without re-evaluations can optimize the classic LeadingOnes benchmark with up to constant noise rates, in sharp contrast to the version with re-evaluations, where only noise with rates \$O(n{\textasciicircum}\{-2\} {\textbackslash}log n)\$ can be tolerated. This result suggests that re-evaluations are much less needed than what was previously thought, and that they actually can be highly detrimental. The insights from our mathematical proofs indicate that this similar results are plausible for other classic benchmarks.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Antipov, Denis and Doerr, Benjamin},
	month = may,
	year = {2025},
	note = {arXiv:2409.00306 [cs]},
	keywords = {evolution, ga, gp, noise, Computer Science - Neural and Evolutionary Computing, evoflock, robustness, variance},
	annote = {Comment: Full version of the paper accepted to IJCAI 2025},
	file = {Preprint PDF:/Users/cwr/Zotero/storage/JCBJ2N4W/Antipov and Doerr - 2025 - Evolutionary Algorithms Are Significantly More Robust to Noise When They Ignore It.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/7UQRFVAT/2409.html:text/html},
}

@article{aoki_simulation_1982,
	title = {A simulation study of the schooling mechanism in fish},
	volume = {48},
	url = {http://dx.doi.org/10.2331/suisan.48.1081},
	doi = {10.2331/suisan.48.1081},
	number = {8},
	journal = {Bulletin of the Japanese society of scientific fisheries},
	author = {Aoki, Ichiro},
	year = {1982},
	keywords = {collective, locomotion, self\_organizing, motion, biology, boids, fish, ocean, emergence, history},
	pages = {1081--1088},
}


@article{baydin_automatic_2018,
	title = {Automatic {Differentiation} in {Machine} {Learning}: a {Survey}},
	volume = {18},
	issn = {1533-7928},
	shorttitle = {Automatic {Differentiation} in {Machine} {Learning}},
	url = {http://jmlr.org/papers/v18/17-468.html},
	abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply “autodiff”, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names “dynamic computational graphs” and “differentiable programming.” We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms “autodiff”, “automatic differentiation”, and “symbolic differentiation” as these are encountered more and more in machine learning settings.},
	number = {153},
	urldate = {2025-07-08},
	journal = {Journal of Machine Learning Research},
	author = {Baydin, Atilim Gunes and Pearlmutter, Barak A. and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
	year = {2018},
	keywords = {autodiff, calculus, differentiable, differentiable programming, history, math, optimization, survey},
	pages = {1--43},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/QTIMAFEZ/Baydin et al. - 2018 - Automatic Differentiation in Machine Learning a Survey.pdf:application/pdf},
}

@article{bhattacharya_collective_2010,
	title = {Collective decision making in cohesive flocks},
	volume = {12},
	issn = {1367-2630},
	url = {http://arxiv.org/abs/1007.4453},
	doi = {10.1088/1367-2630/12/9/093019},
	abstract = {Most of us must have been fascinated by the eye catching displays of collectively moving animals. Schools of fish can move in a rather orderly fashion and then change direction amazingly abruptly. There are a huge number of further examples both from the living and the non-living world for phenomena during which the many interacting, permanently moving units seem to arrive at a common behavioural pattern taking place in a short time. As a paradigm of this type of phenomena we consider the problem of how birds arrive at a decision resulting in their synchronized landing. We introduce a simple model to interpret this process. Collective motion prior to landing is modelled using a simple self-propelled particle (SPP) system with a new kind of boundary condition, while the tendency and the sudden propagation of the intention of landing is introduced through rules analogous to the random field Ising model in an external field. We show that our approach is capable of capturing the most relevant features of collective decision making in a system of units with a variance of individual intentions and being under an increasing level of pressure to switch states. We find that as a function of the few parameters of our model the collective switching from the flying to the landing state is indeed much sharper than the distribution of the individual landing intentions. The transition is accompanied by a number of interesting features discussed in this report.},
	number = {9},
	urldate = {2025-06-28},
	journal = {New Journal of Physics},
	author = {Bhattacharya, K. and Vicsek, Tamás},
	month = sep,
	year = {2010},
	note = {arXiv:1007.4453 [physics]},
	keywords = {Physics - Biological Physics},
	pages = {093019},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/XDLLXLUB/Bhattacharya and Vicsek - 2010 - Collective decision making in cohesive flocks.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/YUVQF8VF/1007.html:text/html},
}

@misc{brambati_learning_2025,
	title = {Learning to flock in open space by avoiding collisions and staying together},
	url = {http://arxiv.org/abs/2506.15587},
	doi = {10.48550/arXiv.2506.15587},
	abstract = {We investigate the emergence of cohesive flocking in open, boundless space using a multi-agent reinforcement learning framework. Agents integrate positional and orientational information from their closest topological neighbours and learn to balance alignment and attractive interactions by optimizing a local cost function that penalizes both excessive separation and close-range crowding. The resulting Vicsek-like dynamics is robust to algorithmic implementation details and yields cohesive collective motion with high polar order. The optimal policy is dominated by strong aligning interactions when agents are sufficiently close to their neighbours, and a flexible combination of alignment and attraction at larger separations. We further characterize the internal structure and dynamics of the resulting groups using liquid-state metrics and neighbour exchange rates, finding qualitative agreement with empirical observations in starling flocks. These results suggest that flocking may emerge in groups of moving agents as an adaptive response to the biological imperatives of staying together while avoiding collisions.},
	urldate = {2025-06-22},
	publisher = {arXiv},
	author = {Brambati, Martino and Celani, Antonio and Gherardi, Marco and Ginelli, Francesco},
	month = jun,
	year = {2025},
	note = {arXiv:2506.15587 [cond-mat]},
	keywords = {collective, learning, boids, steering, Condensed Matter - Soft Condensed Matter, fitness, flocking, reinforcement learning, evoflock},
	annote = {Comment: 13 pages + appendices},
	file = {Preprint PDF:/Users/cwr/Zotero/storage/MCBEH9XD/Brambati et al. - 2025 - Learning to flock in open space by avoiding collisions and staying together.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/KLEY5ZGX/2506.html:text/html},
}

@misc{choi_flocking_2025,
	title = {Flocking with random non-reciprocal interactions},
	url = {http://arxiv.org/abs/2506.22060},
	doi = {10.48550/arXiv.2506.22060},
	abstract = {Flocking is ubiquitous in nature and emerges due to short or long range alignment interactions among self-propelled agents. Two unfriendly species that anti-align or even interact non-reciprocally show more complex collective phenomena, ranging from parallel and anti-parallel flocking over runand chase behavior to chiral phases. Whether flocking or any of these collective phenomena can survive in the presence of a large number of species with random non-reciprocal interactions remained elusive so far. As a first step here the extreme case of a Vicsek-like model with fully random nonreciprocal interactions between the individual particles is considered. As soon as the alignment bias is of the same order as the random interactions the ordered flocking phase occurs, but deep within this phase, the random non-reciprocal interactions can still support global chiral and oscillating states in which the collective movement direction rotates or oscillates slowly. For short-range interactions, moreover, even without alignment bias self-organized cliques emerge, in which medium size clusters of particles that have predominantly aligning interactions meet accidentally and stay together for macroscopic times. These results may serve as a starting point for the study of multi-species flocking models with non-random but complex non-reciprocal inter-species interactions.},
	urldate = {2025-07-05},
	publisher = {arXiv},
	author = {Choi, Jiwon and Noh, Jae Dong and Rieger, Heiko},
	month = jun,
	year = {2025},
	note = {arXiv:2506.22060 [cond-mat]},
	keywords = {behavior, boids, steering, group, species, Condensed Matter - Soft Condensed Matter, Condensed Matter - Statistical Mechanics, flocking, evoflock, asymmetry},
	annote = {Comment: 9 pages, 7 figures},
	file = {Preprint PDF:/Users/cwr/Zotero/storage/FXEMK87Z/Choi et al. - 2025 - Flocking with random non-reciprocal interactions.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/HZCRTSZK/2506.html:text/html},
}

@misc{cornelisse_building_2025,
	title = {Building reliable sim driving agents by scaling self-play},
	url = {http://arxiv.org/abs/2502.14706},
	doi = {10.48550/arXiv.2502.14706},
	abstract = {Simulation agents are essential for designing and testing systems that interact with humans, such as autonomous vehicles (AVs). These agents serve various purposes, from benchmarking AV performance to stress-testing system limits, but all applications share one key requirement: reliability. To enable sound experimentation, a simulation agent must behave as intended. It should minimize actions that may lead to undesired outcomes, such as collisions, which can distort the signal-to-noise ratio in analyses. As a foundation for reliable sim agents, we propose scaling self-play to thousands of scenarios on the Waymo Open Motion Dataset under semi-realistic limits on human perception and control. Training from scratch on a single GPU, our agents solve almost the full training set within a day. They generalize to unseen test scenes, achieving a 99.8\% goal completion rate with less than 0.8\% combined collision and off-road incidents across 10,000 held-out scenarios. Beyond in-distribution generalization, our agents show partial robustness to out-of-distribution scenes and can be fine-tuned in minutes to reach near-perfect performance in such cases. We open-source the pre-trained agents and integrate them with a batched multi-agent simulator. Demonstrations of agent behaviors can be viewed at https://sites.google.com/view/reliable-sim-agents, and we open-source our agents at https://github.com/Emerge-Lab/gpudrive.},
	urldate = {2025-07-08},
	publisher = {arXiv},
	author = {Cornelisse, Daphne and Pandya, Aarav and Joseph, Kevin and Suárez, Joseph and Vinitsky, Eugene},
	month = may,
	year = {2025},
	note = {arXiv:2502.14706 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
	annote = {Comment: v3},
	file = {Preprint PDF:/Users/cwr/Zotero/storage/MEJMVDWW/Cornelisse et al. - 2025 - Building reliable sim driving agents by scaling self-play.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/XJWY294U/2502.html:text/html},
}

@article{cucker_emergent_2007,
	title = {Emergent {Behavior} in {Flocks}},
	volume = {52},
	issn = {1558-2523},
	url = {https://ieeexplore.ieee.org/abstract/document/4200853},
	doi = {10.1109/TAC.2007.895842},
	abstract = {We provide a model (for both continuous and discrete time) describing the evolution of a flock. Our model is parameterized by a constant beta capturing the rate of decay-which in our model is polynomial-of the influence between birds in the flock as they separate in space. Our main result shows that when beta{\textless}1/2 convergence of the flock to a common velocity is guaranteed, while for betages1/2 convergence is guaranteed under some condition on the initial positions and velocities of the birds only},
	number = {5},
	urldate = {2024-05-28},
	journal = {IEEE Transactions on Automatic Control},
	author = {Cucker, Felipe and Smale, Steve},
	month = may,
	year = {2007},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {boids, emergence, Computer simulation, Birds, flocking, Consensus reaching problem, Convergence, Councils, Gravity, H infinity control, Marine animals, Mathematics, Polynomials},
	pages = {852--862},
	file = {CuckerSmale.pdf:/Users/cwr/Zotero/storage/VXSA35TQ/CuckerSmale.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/cwr/Zotero/storage/GRZMMULY/4200853.html:text/html;Submitted Version:/Users/cwr/Zotero/storage/JRFRZYBY/Cucker and Smale - 2007 - Emergent Behavior in Flocks.pdf:application/pdf},
}

@book{darwin_origin_1859,
	address = {London},
	title = {On the {Origin} of {Species} by {Means} of {Natural} {Selection}},
	publisher = {Murray},
	author = {Darwin, Charles},
	year = {1859},
	keywords = {evolution},
	annote = { or the Preservation of Favored Races in the Struggle for Life},
}

@book{dimock_aerodynamic_2003,
	address = {1801 Alexander Bell Drive, Suite 500, Reston, VA 20191–4344},
	title = {The {Aerodynamic} {Benefits} of {Self}-{Organization} in {Bird} {Flocks}},
	abstract = {Natural aggregation processes such as the familiar flocking of birds have been accurately modeled using a simple, decentralized controller. Variations on this ” boid” controller typically involve three or more control laws, each with an associated control gain and sensor range. In this paper, the boid controller is fitted with an additional rule designed to produce aerodynamically-efficient formations, such as those exploited by migratory birds and hypothetical unmanned aerial vehicles. A simple genetic algorithm is then used to optimize the control parameters for minimum power consumption in a flock of simulated birds. This report focuses on the development and utility of the flocking simulator as a fitness function for the GA. Preliminary results indicate that average power consumption can be significantly reduced with the modified, optimized boid controller.},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Dimock, Glen A. and Selig, Michael S.},
	month = jan,
	year = {2003},
	keywords = {collective, self\_organizing, shape, flock, steering, emergence, birds, swarm\_intelligence, group, formations, bird\_flight},
}

@book{holland_adaptation_1975,
    title={Adaptation in Natural and Artificial Systems},
    author={Holland, John},
    year={1975},
    publisher = {MIT Press},
}

@article{jaderberg_human-level_2019,
	title = {Human-level performance in first-person multiplayer games with population-based deep reinforcement learning},
	volume = {364},
	issn = {0036-8075, 1095-9203},
	url = {http://arxiv.org/abs/1807.01281},
	doi = {10.1126/science.aau6249},
	abstract = {Recent progress in artificial intelligence through reinforcement learning (RL) has shown great success on increasingly complex single-agent environments and two-player turn-based games. However, the real-world contains multiple agents, each learning and acting independently to cooperate and compete with other agents, and environments reflecting this degree of complexity remain an open challenge. In this work, we demonstrate for the first time that an agent can achieve human-level in a popular 3D multiplayer first-person video game, Quake III Arena Capture the Flag, using only pixels and game points as input. These results were achieved by a novel two-tier optimisation process in which a population of independent RL agents are trained concurrently from thousands of parallel matches with agents playing in teams together and against each other on randomly generated environments. Each agent in the population learns its own internal reward signal to complement the sparse delayed reward from winning, and selects actions using a novel temporally hierarchical representation that enables the agent to reason at multiple timescales. During game-play, these agents display human-like behaviours such as navigating, following, and defending based on a rich learned representation that is shown to encode high-level game knowledge. In an extensive tournament-style evaluation the trained agents exceeded the win-rate of strong human players both as teammates and opponents, and proved far stronger than existing state-of-the-art agents. These results demonstrate a significant jump in the capabilities of artificial agents, bringing us closer to the goal of human-level intelligence.},
	number = {6443},
	urldate = {2024-07-03},
	journal = {Science},
	author = {Jaderberg, Max and Czarnecki, Wojciech M. and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C. and Morcos, Ari S. and Ruderman, Avraham and Sonnerat, Nicolas and Green, Tim and Deason, Louise and Leibo, Joel Z. and Silver, David and Hassabis, Demis and Kavukcuoglu, Koray and Graepel, Thore},
	month = may,
	year = {2019},
	note = {arXiv:1807.01281 [cs, stat]},
	keywords = {learning, multiagent, optimization, cooperative, team, strategy, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, reinforcement learning, game, adversarial, self\_play, play, evoflock},
	pages = {859--865},
	file = {arXiv Fulltext PDF:/Users/cwr/Zotero/storage/GJ8XLW3L/Jaderberg et al. - 2019 - Human-level performance in first-person multiplaye.pdf:application/pdf;arXiv.org Snapshot:/Users/cwr/Zotero/storage/SMXAWVNY/1807.html:text/html},
}

@misc{montanari_optimal_2025,
	title = {Optimal flock formation induced by agent heterogeneity},
	url = {http://arxiv.org/abs/2504.12297},
	doi = {10.48550/arXiv.2504.12297},
	abstract = {The study of flocking in biological systems has identified conditions for self-organized collective behavior, inspiring the development of decentralized strategies to coordinate the dynamics of swarms of drones and other autonomous vehicles. Previous research has focused primarily on the role of the time-varying interaction network among agents while assuming that the agents themselves are identical or nearly identical. Here, we depart from this conventional assumption to investigate how inter-individual differences between agents affect the stability and convergence in flocking dynamics. We show that flocks of agents with optimally assigned heterogeneous parameters significantly outperform their homogeneous counterparts, achieving 20-40\% faster convergence to desired formations across various control tasks. These tasks include target tracking, flock formation, and obstacle maneuvering. In systems with communication delays, heterogeneity can enable convergence even when flocking is unstable for identical agents. Our results challenge existing paradigms in multi-agent control and establish system disorder as an adaptive, distributed mechanism to promote collective behavior in flocking dynamics.},
	urldate = {2025-04-20},
	publisher = {arXiv},
	author = {Montanari, Arthur N. and Barioni, Ana Elisa D. and Duan, Chao and Motter, Adilson E.},
	month = apr,
	year = {2025},
	note = {arXiv:2504.12297 [cond-mat]},
	keywords = {autonomous, boids, steering, multiagent, network, Mathematics - Dynamical Systems, Autonomous vehicles, Electrical Engineering and Systems Science - Systems and Control, flocking, dynamic, Consensus reaching problem, Nonlinear Sciences - Adaptation and Self-Organizing Systems, Condensed Matter - Disordered Systems and Neural Networks, nonlinear, Mathematics - Optimization and Control, Dynamical systems, Computer Science - Systems and Control, multi-agent},
	file = {Preprint PDF:/Users/cwr/Zotero/storage/58EH26TM/Montanari et al. - 2025 - Optimal flock formation induced by agent heterogeneity.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/J86TS8BU/2504.html:text/html},
}

@inproceedings{reynolds_flocks_1987,
	address = {New York, NY},
	series = {{SIGGRAPH} '87},
	title = {Flocks, {Herds} and {Schools}: {A} {Distributed} {Behavioral} {Model}},
	volume = {21},
	copyright = {All rights reserved},
	isbn = {0-89791-227-6},
	url = {http://graphics.stanford.edu/courses/cs448-01-spring/papers/reynolds.pdf},
	doi = {10.1145/37401.37406},
	abstract = {The aggregate motion of a flock of birds, a herd of land animals, or a school of fish is a beautiful and familiar part of the natural world. But this type of complex motion is rarely seen in computer animation. This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually. The simulated flock is an elaboration of a particle systems, with the simulated birds being the particles. The aggregate motion of the simulated flock is created by a distributed behavioral model much like that at work in a natural flock; the birds choose their own course. Each simulated bird is implemented as an independent actor that navigates according to its local perception of the dynamic environment, the laws of simulated physics that rule its motion, and a set of behaviors programmed into it by the "animator." The aggregate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds.},
	booktitle = {Proceedings of the 14th annual conference on {Computer} graphics and interactive techniques},
	publisher = {ACM},
	author = {Reynolds, Craig W.},
	editor = {Stone, M. C.},
	month = jul,
	year = {1987},
	keywords = {crowd, flock, steering, emergence, inverse\_emergence, distributed, group, lisp},
	pages = {25--34},
}

@incollection{reynolds_evolved_1993,
	title = {An {Evolved}, {Vision}-{Based} {Behavioral} {Model} of {Coordinated} {Group} {Motion}},
	isbn = {978-0-262-28715-9},
	url = {https://doi.org/10.7551/mitpress/3116.003.0052},
	booktitle = {From {Animals} to {Animats} 2: {Proceedings} of the {Second} {International} {Conference} on {Simulation} of {Adaptive} {Behavior}},
	publisher = {The MIT Press},
	author = {Reynolds, Craig W.},
	month = apr,
	year = {1993},
	doi = {10.7551/mitpress/3116.003.0052},
	note = {\_eprint: https://direct.mit.edu/book/chapter-pdf/2314157/9780262287159\_cby.pdf},
	file = {PDF:/Users/cwr/Zotero/storage/GK3G9VKB/Reynolds - 1993 - An Evolved, Vision-Based Behavioral Model of Coordinated Group Motion.pdf:application/pdf},
}

@article{robbins_stochastic_1951,
	title = {A {Stochastic} {Approximation} {Method}},
	volume = {22},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-22/issue-3/A-Stochastic-Approximation-Method/10.1214/aoms/1177729586.full},
	doi = {10.1214/aoms/1177729586},
	abstract = {Let \$M(x)\$ denote the expected value at level \$x\$ of the response to a certain experiment. \$M(x)\$ is assumed to be a monotone function of \$x\$ but is unknown to the experimenter, and it is desired to find the solution \$x = {\textbackslash}theta\$ of the equation \$M(x) = {\textbackslash}alpha\$, where \${\textbackslash}alpha\$ is a given constant. We give a method for making successive experiments at levels \$x\_1,x\_2,{\textbackslash}cdots\$ in such a way that \$x\_n\$ will tend to \${\textbackslash}theta\$ in probability.},
	number = {3},
	urldate = {2025-07-08},
	journal = {The Annals of Mathematical Statistics},
	author = {Robbins, Herbert and Monro, Sutton},
	month = sep,
	year = {1951},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {400--407},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/LH7SEM7N/Robbins and Monro - 1951 - A Stochastic Approximation Method.pdf:application/pdf},
}

@inproceedings{stonedahl_finding_2011,
	address = {Berlin, Heidelberg},
	title = {Finding {Forms} of {Flocking}: {Evolutionary} {Search} in {ABM} {Parameter}-{Spaces}},
	isbn = {978-3-642-18345-4},
	shorttitle = {Finding {Forms} of {Flocking}},
	doi = {10.1007/978-3-642-18345-4_5},
	abstract = {While agent-based models (ABMs) are becoming increasingly popular for simulating complex and emergent phenomena in many fields, understanding and analyzing ABMs poses considerable challenges. ABM behavior often depends on many model parameters, and the task of exploring a model’s parameter space and discovering the impact of different parameter settings can be difficult and time-consuming. Exhaustively running the model with all combinations of parameter settings is generally infeasible, but judging behavior by varying one parameter at a time risks overlooking complex nonlinear interactions between parameters. Alternatively, we present a case study in computer-aided model exploration, demonstrating how evolutionary search algorithms can be used to probe for several qualitative behaviors (convergence, non-convergence, volatility, and the formation of vee shapes) in two different flocking models. We also introduce a new software tool (BehaviorSearch) for performing parameter search on ABMs created in the NetLogo modeling environment.},
	language = {en},
	booktitle = {Multi-{Agent}-{Based} {Simulation} {XI}},
	publisher = {Springer},
	author = {Stonedahl, Forrest and Wilensky, Uri},
	editor = {Bosse, Tibor and Geller, Armando and Jonker, Catholijn M.},
	year = {2011},
	keywords = {behavior, collective, evolution, boids, algorithm, swarm, ga, flocking, genetic algorithms, inverse\_problems, inverse\_design, ABM, agent-based modeling, model exploration, multi-agent simulation, parameter search},
	pages = {61--75},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/WAY4AQY3/Stonedahl and Wilensky - 2011 - Finding Forms of Flocking Evolutionary Search in .pdf:application/pdf},
}

@book{sutton_reinforcement_1998,
	title = {Reinforcement {Learning}: {An} {Introduction}},
	url = {http://www.cs.ualberta.ca/~sutton/book/the-book.html},
	abstract = {This introductory textbook on reinforcement learning is targeted toward engineers and scientists in artificial intelligence, operations research, neural networks, and control systems, and we hope it will also be of interest to psychologists and neuroscientists. It also contains several new results. An html version is available.},
	publisher = {MIT Press},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	year = {1998},
	keywords = {computational learning machine reinforcement supervised wleformativeeassessment},
}

@incollection{syswerda_study_1991,
	address = {Amsterdam},
	title = {A {Study} of {Reproduction} in {Generational} and {Steady}-{State} {Genetic} {Algorithms}},
	volume = {1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080506845500094},
	abstract = {Two techniques of population control are currently used in the field of serial genetic algorithms: generational and steady state. Although they have been used somewhat interchangeably in the past, it has become apparent that the two techniques are actually quite different. In this paper, I study the behavior of each with regard to reproduction, and show that while each can be made similar with respect to the schema theorem, in practice their behavior is quite different.},
	language = {en},
	urldate = {2022-12-04},
	booktitle = {Foundations of {Genetic} {Algorithms}},
	publisher = {Elsevier},
	author = {Syswerda, Gilbert},
	editor = {Rawlins, Gregory J. E.},
	month = jan,
	year = {1991},
	doi = {10.1016/B978-0-08-050684-5.50009-4},
	keywords = {algorithm, ga, gp, population, Evolutionary computation, generational reproduction, reproduction, steady-state reproduction},
	pages = {94--101},
	file = {ScienceDirect Snapshot:/Users/cwr/Zotero/storage/4N3G8GA6/B9780080506845500094.html:text/html;Syswerda - 1991 - A Study of Reproduction in Generational and Steady.pdf:/Users/cwr/Zotero/storage/KBYH77KJ/Syswerda - 1991 - A Study of Reproduction in Generational and Steady.pdf:application/pdf},
}
