
@article{aoki_simulation_1982,
	title = {A simulation study of the schooling mechanism in fish},
	volume = {48},
	url = {http://dx.doi.org/10.2331/suisan.48.1081},
	doi = {10.2331/suisan.48.1081},
	number = {8},
	journal = {Bulletin of the Japanese society of scientific fisheries},
	author = {Aoki, Ichiro},
	year = {1982},
	keywords = {collective, locomotion, self\_organizing, motion, biology, boids, fish, ocean, emergence, history},
	pages = {1081--1088},
}


@article{baydin_automatic_2018,
	title = {Automatic {Differentiation} in {Machine} {Learning}: a {Survey}},
	volume = {18},
	issn = {1533-7928},
	shorttitle = {Automatic {Differentiation} in {Machine} {Learning}},
	url = {http://jmlr.org/papers/v18/17-468.html},
	abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply “autodiff”, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names “dynamic computational graphs” and “differentiable programming.” We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms “autodiff”, “automatic differentiation”, and “symbolic differentiation” as these are encountered more and more in machine learning settings.},
	number = {153},
	urldate = {2025-07-08},
	journal = {Journal of Machine Learning Research},
	author = {Baydin, Atilim Gunes and Pearlmutter, Barak A. and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
	year = {2018},
	keywords = {autodiff, calculus, differentiable, differentiable programming, history, math, optimization, survey},
	pages = {1--43},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/QTIMAFEZ/Baydin et al. - 2018 - Automatic Differentiation in Machine Learning a Survey.pdf:application/pdf},
}

@article{bhattacharya_collective_2010,
	title = {Collective decision making in cohesive flocks},
	volume = {12},
	issn = {1367-2630},
	url = {http://arxiv.org/abs/1007.4453},
	doi = {10.1088/1367-2630/12/9/093019},
	abstract = {Most of us must have been fascinated by the eye catching displays of collectively moving animals. Schools of fish can move in a rather orderly fashion and then change direction amazingly abruptly. There are a huge number of further examples both from the living and the non-living world for phenomena during which the many interacting, permanently moving units seem to arrive at a common behavioural pattern taking place in a short time. As a paradigm of this type of phenomena we consider the problem of how birds arrive at a decision resulting in their synchronized landing. We introduce a simple model to interpret this process. Collective motion prior to landing is modelled using a simple self-propelled particle (SPP) system with a new kind of boundary condition, while the tendency and the sudden propagation of the intention of landing is introduced through rules analogous to the random field Ising model in an external field. We show that our approach is capable of capturing the most relevant features of collective decision making in a system of units with a variance of individual intentions and being under an increasing level of pressure to switch states. We find that as a function of the few parameters of our model the collective switching from the flying to the landing state is indeed much sharper than the distribution of the individual landing intentions. The transition is accompanied by a number of interesting features discussed in this report.},
	number = {9},
	urldate = {2025-06-28},
	journal = {New Journal of Physics},
	author = {Bhattacharya, K. and Vicsek, Tamás},
	month = sep,
	year = {2010},
	note = {arXiv:1007.4453 [physics]},
	keywords = {Physics - Biological Physics},
	pages = {093019},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/XDLLXLUB/Bhattacharya and Vicsek - 2010 - Collective decision making in cohesive flocks.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/YUVQF8VF/1007.html:text/html},
}

@misc{brambati_learning_2025,
	title = {Learning to flock in open space by avoiding collisions and staying together},
	url = {http://arxiv.org/abs/2506.15587},
	doi = {10.48550/arXiv.2506.15587},
	abstract = {We investigate the emergence of cohesive flocking in open, boundless space using a multi-agent reinforcement learning framework. Agents integrate positional and orientational information from their closest topological neighbours and learn to balance alignment and attractive interactions by optimizing a local cost function that penalizes both excessive separation and close-range crowding. The resulting Vicsek-like dynamics is robust to algorithmic implementation details and yields cohesive collective motion with high polar order. The optimal policy is dominated by strong aligning interactions when agents are sufficiently close to their neighbours, and a flexible combination of alignment and attraction at larger separations. We further characterize the internal structure and dynamics of the resulting groups using liquid-state metrics and neighbour exchange rates, finding qualitative agreement with empirical observations in starling flocks. These results suggest that flocking may emerge in groups of moving agents as an adaptive response to the biological imperatives of staying together while avoiding collisions.},
	urldate = {2025-06-22},
	publisher = {arXiv},
	author = {Brambati, Martino and Celani, Antonio and Gherardi, Marco and Ginelli, Francesco},
	month = jun,
	year = {2025},
	note = {arXiv:2506.15587 [cond-mat]},
	keywords = {collective, learning, boids, steering, Condensed Matter - Soft Condensed Matter, fitness, flocking, reinforcement learning, evoflock},
	annote = {Comment: 13 pages + appendices},
	file = {Preprint PDF:/Users/cwr/Zotero/storage/MCBEH9XD/Brambati et al. - 2025 - Learning to flock in open space by avoiding collisions and staying together.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/KLEY5ZGX/2506.html:text/html},
}

@misc{cornelisse_building_2025,
	title = {Building reliable sim driving agents by scaling self-play},
	url = {http://arxiv.org/abs/2502.14706},
	doi = {10.48550/arXiv.2502.14706},
	abstract = {Simulation agents are essential for designing and testing systems that interact with humans, such as autonomous vehicles (AVs). These agents serve various purposes, from benchmarking AV performance to stress-testing system limits, but all applications share one key requirement: reliability. To enable sound experimentation, a simulation agent must behave as intended. It should minimize actions that may lead to undesired outcomes, such as collisions, which can distort the signal-to-noise ratio in analyses. As a foundation for reliable sim agents, we propose scaling self-play to thousands of scenarios on the Waymo Open Motion Dataset under semi-realistic limits on human perception and control. Training from scratch on a single GPU, our agents solve almost the full training set within a day. They generalize to unseen test scenes, achieving a 99.8\% goal completion rate with less than 0.8\% combined collision and off-road incidents across 10,000 held-out scenarios. Beyond in-distribution generalization, our agents show partial robustness to out-of-distribution scenes and can be fine-tuned in minutes to reach near-perfect performance in such cases. We open-source the pre-trained agents and integrate them with a batched multi-agent simulator. Demonstrations of agent behaviors can be viewed at https://sites.google.com/view/reliable-sim-agents, and we open-source our agents at https://github.com/Emerge-Lab/gpudrive.},
	urldate = {2025-07-08},
	publisher = {arXiv},
	author = {Cornelisse, Daphne and Pandya, Aarav and Joseph, Kevin and Suárez, Joseph and Vinitsky, Eugene},
	month = may,
	year = {2025},
	note = {arXiv:2502.14706 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
	annote = {Comment: v3},
	file = {Preprint PDF:/Users/cwr/Zotero/storage/MEJMVDWW/Cornelisse et al. - 2025 - Building reliable sim driving agents by scaling self-play.pdf:application/pdf;Snapshot:/Users/cwr/Zotero/storage/XJWY294U/2502.html:text/html},
}

@article{cucker_emergent_2007,
	title = {Emergent {Behavior} in {Flocks}},
	volume = {52},
	issn = {1558-2523},
	url = {https://ieeexplore.ieee.org/abstract/document/4200853},
	doi = {10.1109/TAC.2007.895842},
	abstract = {We provide a model (for both continuous and discrete time) describing the evolution of a flock. Our model is parameterized by a constant beta capturing the rate of decay-which in our model is polynomial-of the influence between birds in the flock as they separate in space. Our main result shows that when beta{\textless}1/2 convergence of the flock to a common velocity is guaranteed, while for betages1/2 convergence is guaranteed under some condition on the initial positions and velocities of the birds only},
	number = {5},
	urldate = {2024-05-28},
	journal = {IEEE Transactions on Automatic Control},
	author = {Cucker, Felipe and Smale, Steve},
	month = may,
	year = {2007},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {boids, emergence, Computer simulation, Birds, flocking, Consensus reaching problem, Convergence, Councils, Gravity, H infinity control, Marine animals, Mathematics, Polynomials},
	pages = {852--862},
	file = {CuckerSmale.pdf:/Users/cwr/Zotero/storage/VXSA35TQ/CuckerSmale.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/cwr/Zotero/storage/GRZMMULY/4200853.html:text/html;Submitted Version:/Users/cwr/Zotero/storage/JRFRZYBY/Cucker and Smale - 2007 - Emergent Behavior in Flocks.pdf:application/pdf},
}

@book{darwin_origin_1859,
	address = {London},
	title = {On the {Origin} of {Species} by {Means} of {Natural} {Selection}},
	publisher = {Murray},
	author = {Darwin, Charles},
	year = {1859},
	keywords = {evolution},
	annote = { or the Preservation of Favored Races in the Struggle for Life},
}

@book{holland_adaptation_1975,
    title={Adaptation in Natural and Artificial Systems},
    author={Holland, John},
    year={1975},
    publisher = {MIT Press},
}

@inproceedings{reynolds_flocks_1987,
	address = {New York, NY},
	series = {{SIGGRAPH} '87},
	title = {Flocks, {Herds} and {Schools}: {A} {Distributed} {Behavioral} {Model}},
	volume = {21},
	copyright = {All rights reserved},
	isbn = {0-89791-227-6},
	url = {http://graphics.stanford.edu/courses/cs448-01-spring/papers/reynolds.pdf},
	doi = {10.1145/37401.37406},
	abstract = {The aggregate motion of a flock of birds, a herd of land animals, or a school of fish is a beautiful and familiar part of the natural world. But this type of complex motion is rarely seen in computer animation. This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually. The simulated flock is an elaboration of a particle systems, with the simulated birds being the particles. The aggregate motion of the simulated flock is created by a distributed behavioral model much like that at work in a natural flock; the birds choose their own course. Each simulated bird is implemented as an independent actor that navigates according to its local perception of the dynamic environment, the laws of simulated physics that rule its motion, and a set of behaviors programmed into it by the "animator." The aggregate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds.},
	booktitle = {Proceedings of the 14th annual conference on {Computer} graphics and interactive techniques},
	publisher = {ACM},
	author = {Reynolds, Craig W.},
	editor = {Stone, M. C.},
	month = jul,
	year = {1987},
	keywords = {crowd, flock, steering, emergence, inverse\_emergence, distributed, group, lisp},
	pages = {25--34},
}

@incollection{reynolds_evolved_1993,
	title = {An {Evolved}, {Vision}-{Based} {Behavioral} {Model} of {Coordinated} {Group} {Motion}},
	isbn = {978-0-262-28715-9},
	url = {https://doi.org/10.7551/mitpress/3116.003.0052},
	booktitle = {From {Animals} to {Animats} 2: {Proceedings} of the {Second} {International} {Conference} on {Simulation} of {Adaptive} {Behavior}},
	publisher = {The MIT Press},
	author = {Reynolds, Craig W.},
	month = apr,
	year = {1993},
	doi = {10.7551/mitpress/3116.003.0052},
	note = {\_eprint: https://direct.mit.edu/book/chapter-pdf/2314157/9780262287159\_cby.pdf},
	file = {PDF:/Users/cwr/Zotero/storage/GK3G9VKB/Reynolds - 1993 - An Evolved, Vision-Based Behavioral Model of Coordinated Group Motion.pdf:application/pdf},
}

@article{robbins_stochastic_1951,
	title = {A {Stochastic} {Approximation} {Method}},
	volume = {22},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-22/issue-3/A-Stochastic-Approximation-Method/10.1214/aoms/1177729586.full},
	doi = {10.1214/aoms/1177729586},
	abstract = {Let \$M(x)\$ denote the expected value at level \$x\$ of the response to a certain experiment. \$M(x)\$ is assumed to be a monotone function of \$x\$ but is unknown to the experimenter, and it is desired to find the solution \$x = {\textbackslash}theta\$ of the equation \$M(x) = {\textbackslash}alpha\$, where \${\textbackslash}alpha\$ is a given constant. We give a method for making successive experiments at levels \$x\_1,x\_2,{\textbackslash}cdots\$ in such a way that \$x\_n\$ will tend to \${\textbackslash}theta\$ in probability.},
	number = {3},
	urldate = {2025-07-08},
	journal = {The Annals of Mathematical Statistics},
	author = {Robbins, Herbert and Monro, Sutton},
	month = sep,
	year = {1951},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {400--407},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/LH7SEM7N/Robbins and Monro - 1951 - A Stochastic Approximation Method.pdf:application/pdf},
}

@book{sutton_reinforcement_1998,
	title = {Reinforcement {Learning}: {An} {Introduction}},
	url = {http://www.cs.ualberta.ca/~sutton/book/the-book.html},
	abstract = {This introductory textbook on reinforcement learning is targeted toward engineers and scientists in artificial intelligence, operations research, neural networks, and control systems, and we hope it will also be of interest to psychologists and neuroscientists. It also contains several new results. An html version is available.},
	publisher = {MIT Press},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	year = {1998},
	keywords = {computational learning machine reinforcement supervised wleformativeeassessment},
}

@incollection{syswerda_study_1991,
	address = {Amsterdam},
	title = {A {Study} of {Reproduction} in {Generational} and {Steady}-{State} {Genetic} {Algorithms}},
	volume = {1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080506845500094},
	abstract = {Two techniques of population control are currently used in the field of serial genetic algorithms: generational and steady state. Although they have been used somewhat interchangeably in the past, it has become apparent that the two techniques are actually quite different. In this paper, I study the behavior of each with regard to reproduction, and show that while each can be made similar with respect to the schema theorem, in practice their behavior is quite different.},
	language = {en},
	urldate = {2022-12-04},
	booktitle = {Foundations of {Genetic} {Algorithms}},
	publisher = {Elsevier},
	author = {Syswerda, Gilbert},
	editor = {Rawlins, Gregory J. E.},
	month = jan,
	year = {1991},
	doi = {10.1016/B978-0-08-050684-5.50009-4},
	keywords = {algorithm, ga, gp, population, Evolutionary computation, generational reproduction, reproduction, steady-state reproduction},
	pages = {94--101},
	file = {ScienceDirect Snapshot:/Users/cwr/Zotero/storage/4N3G8GA6/B9780080506845500094.html:text/html;Syswerda - 1991 - A Study of Reproduction in Generational and Steady.pdf:/Users/cwr/Zotero/storage/KBYH77KJ/Syswerda - 1991 - A Study of Reproduction in Generational and Steady.pdf:application/pdf},
}
