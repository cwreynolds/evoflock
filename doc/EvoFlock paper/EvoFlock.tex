%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
% Evoflock: evolved inverse design of multi-agent motion
% speculative draft paper
%
% May 29, 2025  Begin draft.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[letterpaper]{article}
\usepackage{natbib,alifeconf}

% Used for ALife, not sure I still need them.
\usepackage{calc}
\usepackage[hyphens]{xurl}
\usepackage{hyperref}
\usepackage{tabularx}

% Added 20230421 to allow SIGGRAPH-style “teaser figure'' under title.
\usepackage{authblk}
\usepackage{titlepic}
\usepackage{caption}
\usepackage{float}
\usepackage[T1]{fontenc} % ??? QQQ -- "<"

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \graphicspath{ {images/} {images/fcd5/} }
\graphicspath{ {images/} }

%% For introducing terms which have a special meaning in this work.
\newcommand{\jargon}[1]{\textit{#1}}

%% Use like: {\runID backyard\_oak\_20230113\_2254}
\newcommand{\runID}{\footnotesize}

%% for laying out a row of 4, 6, or 9 images
\newcommand{\igfour}[1]{\includegraphics[width=0.24\linewidth]{#1}}
\newcommand{\igsix}[1]{\includegraphics[width=0.16\linewidth]{#1}}
\newcommand{\ignine}[1]{\includegraphics[width=0.104\linewidth]{#1}}

% small fixed-width font
\newcommand{\stt}[1]{{\small \texttt{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Evoflock: evolved inverse design of multi-agent motion}

\author{Craig Reynolds\authorcr
    unaffiliated researcher\authorcr 
    cwr@red3d.com}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\captionsetup{hypcap=false}

\titlepic{\includegraphics[width=\textwidth]{images/temp_fig_1.png}
\captionof{figure}{800 boids flocking in a space cluttered with obstacles. Behavioral parameters of the boids are determined by inverse design, using multi-objective evolutionary optimization.} 
\label{fig:boid_flock}}

% Remove today's date being inserted after the title/author information.
\date{}

%% Lay out the single column top matter defined above.
\maketitle

% This puts a page number at the bottom center, but too close to text.
% \pagestyle{plain}
% \pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
    This paper describes an automatic method for adjusting or tuning multi-agent motion models. Simulating the motion of bird flocks, human crowds, vehicle traffic, and other multi-agent systems is a widely used computational technique. These simulations model the behavior of a group member (bird, human, or vehicle). The group behaviors (flock, crowd, traffic) emerge from interactions between group members. These models tend to have many numeric control parameters. Although each parameter is understandable in isolation, their interaction can be complex and nonlinear. It can be difficult to know how to adjust which parameters to make a desired change in the group behavior. Changing one aspect of group behavior often causes other aspects to change, leading to a long process of incremental changes. In this work, the desired group behavior is measured with an objective(/fitness/loss) function and optimized with a genetic algorithm.
\end{abstract}

\noindent{\small\textbf{Keywords:} boids, inverse design, optimization, evolutionary computation, genetic algorithm, flocks, herds, schools, crowds, traffic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{images/temp_MOF_HV.png}
    \caption{(A) Normalized multi-objective fitness space. For two objectives, each with scores ranging over [0, 1], a unit square. (B) The \textit{Pareto front} for two mutually conflicting objectives. (Like \textit{reliability} and \textit{affordability} in the hypothetical bridge design example.) The objectives can not all be simultaneously well satisfied. Visually, this is the distance from (1,1) to the red curve. (C) Mostly compatible objectives, more typical of criteria for flock tuning. Here, the Pareto front passes near the global optimum. (D) Scalarization of a multiple-objective fitness value, using \textit{hypervolume}: the product of all objective scores. In this 2D example it is the blue rectangle's \textit{area}.}
    \label{fig:MOF_HV}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}

[[[\textbf{...say something about how I used three objectives to evolve flocking of the type shown in Fig. 1 --- maybe try an experiment with ``open air flocking'' to see if it will work with just separation score...}]]]

[[[\textbf{...the idea of ``a `black box' boid flocking model'' is mentioned twice. Should say more about that. Point out that my approach does not require access to the BB model, nor impose constraints on it (like Matthew needing code subject to auto-diff). Note more generally, this approach does not require a differentiable model, in contrast to an approach based on stochastic gradient descent...}]]]

[[[\textbf{...go through all papers in my Zotero with the tag \textit{evoflock}...}]]]

Simulation models of multi-agent motion are used in many fields, including animation, games, biology, robotic swarms, and urban planning. Several early models include \textit{boids} \citep{reynolds_flocks_1987} and others (see \nameref{sec:related}). All allow creating simulations of flocks, and other group motions.  They tend to produce motion that most observers would recognize as some sort of flock. This paper will refer to bird flocks, with the assumption that other types of group motion (herds, schools, crowds, traffic, drone swarms) can be portrayed with suitable adjustment of the model.

This project addresses the issue of \textit{adjusting} or \textit{tuning} multi-agent motion models, toward a given behavioral goal. For example, modifying a model of bird flocks to instead portray fish schools. Or starting from a model of flocking crows and changing it to represent a flock of sparrows. Or to take a plausibly realistic model of a natural bird flock, and change it, say for storytelling purposes, to convey a flock of birds that are happy, or angry. Similarly, starting from a generic abstract flock model and fitting it to observations of a given species of real birds in nature.

A boids-like simulation model usually has a collection of numeric parameters that control its action. The theme of this work is to automatically determine a set of near-optimal parameters for a simulation-based multi-agent system. The flock model used for these experiments is a predefined hand-written ``black box'' model whose input is a parameter set (consisting of about about 20 numbers). A user provides a fitness(/objective/loss) function which takes a candidate parameter set, runs a simulation, and returns a score reflecting how well the behavioral goals were met. The optimization process runs (for about two hours on a laptop) and produces a high quality parameter set.

Initially, adjusting the parameters is required simply to create group motion that looks like plausible flocking. Any sort of modification to a group motion model, such as the examples mentioned above, required further adjustments to the parameters. Each such adjustment requires selecting which parameter(s) to change, whether it should increase or decrease, and by how much. Often more than one parameter needs changing. The main difficulty is that the effects of control parameters overlap and interact. Changing one usually requires changing others to compensate. Often, the result is that many parameters need to be changed. Sometimes the overall behavior of the model gets worse. It can be a frustrating and time-consuming process.

This paper is about automating that adjustment process using metrics of flock quality and an optimization process. The metrics use multiple objectives. The optimization process used in these experiments is a genetic algorithm.

A summary of (``hyper'')parameters for this framework is given in \ref{table:HyperParameters}.

The anonymized c++ code for this project can be viewed at:
\scriptsize
\url{https://anonymous.4open.science/r/evoflock-9B09/}
\normalsize

A video of flock simulations based on this approach is available here:
\scriptsize
\url{https://www.youtube.com/xxx}
\normalsize
[[[\textbf{fix URL once posted}]]]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.7\textwidth]{images/temp_evo_update.png}
    \caption{One update step of the evolutionary optimization process: (a) randomly select one of the \textit{sub-populations}, (b) from that subpop, randomly select three \textit{individuals} (flock parameter sets), (c) get fitness for each, either by running flock simulations (green), or using the fitness cached (orange) from previous tournaments, (d) sort the three by fitness, (e) the worst (least fit) individual is deleted, (f) the best two individuals mate (\textit{crossover}) to create a new individual, (g) that new individual replaces the worst of the three back in the sub-population.}
    \label{fig:temp_evo_update}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
\label{sec:related}

[[[\textbf{mention self-play}]]]

Since the 1980s various simulation models of bird flocks have been proposed including \textit{boids} \citep{reynolds_flocks_1987} and others (\citet{aoki_simulation_1982}, \citet{cucker_emergent_2007}, \citet{bhattacharya_collective_2010} [[[\textbf{Is this the best citation for Vicsek?}]]]).

Most previous work on automatic tuning for flock models has used reinforcement learning \citep{sutton_reinforcement_1998} as the optimization technique. For example, recent excellent work on high quality \textit{driving agents} for a multi-agent traffic simulation based on self-play using reinforcement learning \citep{cornelisse_building_2025}.

While this paper was being drafted, a preprint was posted \citep{brambati_learning_2025} using reinforcement learning with an objective function very similar to the one used here. Other flock tuning based on reinforcement learning include:
[[[\textbf{cites?}]]].

An early, while not very successful, attempt to tune flock simulations \citep{reynolds_evolved_1993} used \textit{genetic programming}, a variation on the \textit{genetic algorithm} based on arbitrary tree-shaped genomes.

The approach used here was developed as part of a larger ongoing collaboration investigating new approaches to optimization of multi-agent motion. [[[\textbf{cite Matthew's thesis?}]]]

\section{Description of the Technique}
\label{sec:Description}

This section discusses the various components of the optimization process for adjusting parameters of a flock, or other kinds of multi-agent motion model.

\subsection{Optimization with Genetic Algorithms}
\label{subsec:Optimization_with_GA}

Optimization can be used to find a set of simulation parameters that best fit given behavioral goals. The approach described here uses a \textit{genetic algorithm} (GA), a technique based loosely on concepts of biological evolution, as seen in the natural world. Genetic algorithms were first described by \citet{holland_adaptation_1975}. Evolution was first described by \citet{darwin_origin_1859}.

A GA is a stochastic population-based approach to optimization and discovery. They proceed by a random process. For example, a model parameter might be changed by adding a signed zero-centered random value, offsetting the parameter by a small amount from its previous value. A genetic algorithm maintains a \textit{population} of candidate solution. Usually the population contains a fixed number (tens to thousands) of candidate solutions, often called \textit{individuals}. Typically each individual is a fixed-sized vector of numeric parameter values.

Many variations on genetic algorithms have been developed. Sometimes, the entire population of individuals is updated in parallel, as a \textit{generation}, and that process is repeated tens to hundreds of times. The approach used here, known as \textit{steady state} (SSGA) updates individuals one at a time \citep{syswerda_study_1991}. If a generational GA is run for $G$ generations with a population of $P$ individuals, a corresponding SSGA would be run for $G{\times}P$ steps.

[[[\textbf{genome}]]]

[[[\textbf{reproduction / crossover}]]]

[[[\textbf{maybe add diagram of SSGA step}]]]


\subsection{Objective Function}
\label{subsec:ObjectiveFunction}

This work is based on optimizing a set of parameters for a flock (multi-agent motion) model. Optimization procedures are guided by an \textit{objective function}. In many optimization problems, the overall objective is a combination of several, potentially contradictory goals, called multi-objective optimization. 

To motivate this concept, consider building a bridge over a river. A key goal is that the bridge is reliable: it will carry the required loads without collapsing. Another important goal is that the cost of building the bridge is minimized. These criteria are directly opposed. A very strong bridge is reliable but costly. A very cheap bridge is unlikely to be reliable. This trade-off is often called \textit{Pareto optimality}. Tuples of such Pareto optimal values form the \textit{Pareto front}, see Figure \ref{fig:MOF_HV}(b).

Other types of multi-objective optimization have less contradictory goals. The multi-agent motion problem seems to fall into this category. For this application, all that is required is to find parameter sets so that each of the objectives can be well satisfied, see Figure \ref{fig:MOF_HV}(c).

\subsection{Multi-Objective Optimization}
\label{subsec:Multi-Objective}

xxx

[[[\textbf{scalarization}]]]

[[[\textbf{...hypervolume --- mention the product is of objective components clipped above 0: max(o, 0.1)} to allow other components to ``show through'' --- include this floor value to table 1...]]]

\section{Parameter set for a flocking model}
\label{sec:parameter_set}

[[[\textbf{...list the parameters, talk a bit about the flocking model...}]]]

[[[\textbf{...note that flocking model needs to be cleaned up and that I'm using ``evolved speed control''...}]]]

\section{An objective function for flocking}
\label{sec:FlockingObjective}

Having described the components of the optimization framework for this inverse design project (see \nameref{sec:Description}), this section focuses on the specific objective(/fitness/loss) function that was used in this work to optimize a multi-agent motion model for flocking.

The objectives described below are based on measurements made during the flock simulation process. That is, in addition to running the simulation, ``bookkeeping'' code is run while updating each individual boid step, after a flock update, and at the end of a simulation. Those metrics are stored in the flock instance and queried by the evolutionary optimization framework in which the flock simulation is run.

\subsection{Objective for Separation}
\label{subsec:separation_objective}

A key observation is that the birds in a flock are grouped closely together, yet manage to avoid colliding with each other. [[[\textbf{find some citation to back this up?}]]] These goals can be seen as a requirement that the distance between simulated boids fall within a certain distance interval. Specifically, for a given boid, we determine its nearest neighbor, and measure the distance between their centers. A score is computed based on that distance. It is zero if either the distance is too small (potential collision) or the distance is too large (failure to cohere: form a dense flock). It is one in an acceptable range, and piecewise linear ramps transition from one to zero outside this desired range. See Figure \ref{fig:SeparationScore}.

An equally iconic property of natural flocks is that birds are \textit{aligned}, flying on nearly parallel paths with their neighbors. An interesting result of this work is that this alignment appears to \textit{emerge} from the ``acceptable neighbor distance'' criteria. It was \textbf{not} necessary to have an explicit optimization objective for alignment. Simply optimizing to obtain separation appears to \textbf{cause} the alignment.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]
    \centering
    % \includegraphics[width=0.9\textwidth]{images/temp_sep_score.png}
    \includegraphics[width=0.9\linewidth]{images/temp_sep_score.png}
    \caption{Score for desired \textit{separation} distance to a boid's nearest neighbor. This function is highest when the centers of two boids are between 2 and 4 body diameters apart. The default boid body diameter is 1. The \textit{separation} score for an entire flock simulation is the average of this function, over all boids, on all simulation steps. [[[\textbf{TEMP}]]]}
    \label{fig:SeparationScore}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Objective for Obstacle Avoidance}
\label{subsec:avoidance_objective}

The example application in this work can be described as ``flocking in the presence of obstacles'' as shown in Figure \ref{fig:boid_flock}. At each time step, part of each boid's simulation is predicting future obstacle collisions and applying steering force to avoid them. The same code detects obstacle avoidance failures. In simulation, this is a matter of a boid having incorrectly passed through the surface of the obstacle. A kinematic constraint is invoked to move the boid back to the correct side of the boundary. This failure is recorded in a collision counter on each boid. At the end of the flock simulation this is turned into a normalized score of the total number of all collisions over the total number of boid-steps. (Typically in these experiments, a fitness test runs 200 boids for 500 simulation steps, so the final score is total number of collisions over 100,000.) 

For collision avoidance, the goal is not merely to \textit{reduce} the number of collisions but to effectively eliminate them. (An informal goal in these experiments has been {$\leq$}10 collisions per 100,000 boid-steps.) To express this, the normalized obstacle avoidance score (on [0, 1]) is exponentiated to the 500\textsuperscript{th} power. This pushes nearly the whole score's range down near zero, except for a small region near a perfect score of one. This effectively rejects flock parameter sets with more than a handful of collisions per flock simulation.

\subsection{Objective for Flight Speed}
\label{subsec:speed_objective}

Originally, following early boid models \citep{reynolds_flocks_1987}, each boid's flight speed was kinematically clipped to remain below 20 meters per second. Later, a third optimization objective was added to establish a target speed range. A new behavior was added to each boid to apply a force along its direction of motion to adjust its flight speed toward the desired range. The strength of this behavior became one of the flock parameters being optimized in the inverse flock design process.

Flight speed \textit{can} be left to “float” during optimization. Unfortuately there is an annoyingly large basin of attractions around not moving (speed = 0). In any case, an inverse design problem probably assumes some range of valid speeds. This suggests that the speed range should be given in the inverse design problem statement. For example, modeling a flock of finches and a flock of swallows would imply very different speed ranges. Figure \ref{fig:speed_score} shows a speed score function used in these experiments. It has a target range in the interval [19, 21] with a fixed support ramping down to zero outside that range.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]
    \centering
    % \includegraphics[width=0.9\textwidth]{images/temp_speed_score.png}
    \includegraphics[width=0.9\linewidth]{images/temp_speed_score.png}
    \caption{Score for desired boid \textit{speed}, here 20 meters per second. This function is highest when speed is between 19 and 21 m/s. The \textit{speed} score for an entire flock simulation is the average of this function, over all boids, on all simulation steps. [[[\textbf{TEMP}]]]}
    \label{fig:speed_score}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Adjusting Objectives}
\label{subsec:adjust_objective}

[[[\textbf{...need to say something (here?) about the nonlinearities used on the scores: remapInterval() for obstacle non-collisions and emphasizeHighScores() for separation...}]]]

[[[\textbf{...for obstacleCollisionsScore() --- do experiments comparing emphasizeHighScores() with a simple exponential...}]]]

\subsection{Adding an objective}
\label{subsec:add_objective}

[[[\textbf{...make experiment with goal of increasing path curvature. If it works describe here. Otherwise put it in \nameref{sec:future}...}]]]

[[[\textbf{...need to say something (here?) about the nonlinearities used on the scores: remapInterval() for obstacle non-collisions and emphasizeHighScores() for separation...}]]]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[b]
\centering
\begin{tabular}{ | l | c | c | }
    \hline
    % \multicolumn{3}{|c|}{Project Parameters} \\
    \textbf{Description} & \textbf{Value} & \textbf{Notes} \\
    \hline
    boids per flock & 200 &  \\
    flock simulation steps & 500 & ``16.6 sec'' \\
    simulation time step & 1/30 seconds & \\
    \hline
    boid body diameter & 1 meter & \\
    boid body mass & 1 kilogram & \\
    boid max force & < 100 newtons & \\
    boid speed range & 19 to 21 m/s & \\
    obs avoid exponent & 500 & \\
    k nearest neighbors & 7 & cf. StarFlag \\
    \hline
    evolution population & 500, 1000 & \\
    evolution steps & 30,000 & SSGA \\
    \hline
    run time: flock sim & $\sim$0.2 seconds & $200{\times}500$ \\
    run time: evolution & $\sim$2 hours & \\
    \hline
\end{tabular}
\caption{Detailed (``hyper'')parameters for the evolutionary inverse design framework. Run times are on a 2021 Apple Macbook Pro M1 Max.}
\label{table:HyperParameters}
\end{table}

\begin{table}[b]
\centering
\begin{tabular}{ | l | c | c | }
    \hline
    \textbf{Description} & \textbf{Range} & \textbf{Notes} \\
    \hline
    max force & [0, 100] & Newtons \\
    forward weight & [0, 100] &  \\
    separate weight & [0, 100] &  \\
    align weight & [0, 100] &  \\
    cohere weight & [0, 100] &  \\
    predictive avoid weight & [0, 100] &  \\
    static avoid weight & [0, 100] &  \\
    \hline
\end{tabular}
\caption{Flock model parameters subject to optimization. These are a vector of scalar values, each with an associated range. They are initially randomized then adjusted over time according to the objective function.}
\label{table:flock-parameters}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}
\label{sec:Conclusions}

This work suggests that evolutionary optimization, via a genetic algorithm, can successfully optimize a set of parameters for a ``black box'' boid flocking model. This suggests that other similar multi-agent motion models --- for example, multi robot terrain search --- might well be solved using a genetic algorithm in a similar way, using an objective with some similarity to the one discussed in \nameref{sec:FlockingObjective}.

[[[\textbf{should this be in the introduction? Say something about using deep reinforcement learning for flocks, etc.}]]] One advantage of using evolutionary optimization for this type of inverse design problem is that the multi-agent simulation can be treated as a ``black box.'' As such, there are few constraints on how the simulation is implemented. For example, to use \textit{stochastic gradient descent} (SGD) \citep{robbins_stochastic_1951} the flock model must be differentiable, either analytically or with \textit{automatic differentiation} \citep{baydin_automatic_2018}. Conversely, evolutionary optimization only requires the measured scalar fitness of a simulation, no gradients are used.

[[[\textbf{I said this above, should it be here, or simply call back to it? \textit{An equally iconic property of natural flocks is that birds are aligned, flying on nearly parallel paths with their neighbors. An interesting result of this work is that this alignment appears to \textit{emerge} from the ``acceptable neighbor distance'' criteria. It was \textbf{not} necessary to have an explicit optimization objective for alignment.}}]]]

\section{Limitations}
\label{sec:limitations}

[[[\textbf{...for speed score and separation score: does it matter if the ramps on either side of the sweet spot are there? Should try a test...}]]]

[[[\textbf{...discuss the ``ignoring noise'' paper...}]]]

\section{Future Work}
\label{sec:future}

[[[\textbf{...I plan to try adding a fourth objective --- perhaps for path curvature --- as an exercise to talk about more advanced inverse design problems --- but if not, it should be mentioned here...}]]]

[[[\textbf{...experiment with open space flocking --- no obstacles --- perhaps in conjunction with path curvature objective...}]]]

\section{Acknowledgements}
\label{sec:ack}

[[[\textbf{Gilbert, Matthew, Jennifer, Wahrman(?), Inman Harvey?}]]]

\bibliographystyle{apalike}
\bibliography{EvoFlock.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Appendix / Supplemental Materials

\appendix
\onecolumn
\section{Appendix}
\label{sec:appendix}

\end{document}